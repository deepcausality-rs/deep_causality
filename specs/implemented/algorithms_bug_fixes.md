SURD exclusion principle zeros higher-order info instead of capping at max_prev_level

# Summary
- **Context**: The SURD-states algorithm decomposes mutual information into Synergistic, Unique, and Redundant components. The exclusion principle (lines 357-376 in `surd_algo.rs`) prevents double-counting by adjusting specific information values across hierarchical interaction orders.
- **Bug**: In `surd_algo.rs`, when a higher-order term has specific information less than the maximum of lower-order terms, the algorithm incorrectly sets it to `0.0` instead of `max_prev_level`.
- **Actual vs. expected**: The current implementation zeros out contributions that should be preserved but adjusted to prevent double-counting, while the correct behavior (as implemented in the CDL variant) is to set them to `max_prev_level` to maintain the hierarchical information flow.
- **Impact**: This causes incorrect decomposition of information into redundant, unique, and synergistic components, particularly affecting scenarios where synergistic terms have state-specific information values that fall below single-variable maxima.

# Code with bug

In `deep_causality_algorithms/src/causal_discovery/surd/surd_algo.rs` (lines 357-376):

```rust
if let Some(&max_len) = lens.iter().max() {
    for l in 1..max_len {
        let max_prev_level = i1_sorted
            .iter()
            .zip(&lens)
            .filter(|&(_, &len)| len == l)
            .map(|(&val, _)| val)
            .fold(f64::NEG_INFINITY, f64::max);
        if max_prev_level.is_finite() {
            i1_sorted
                .iter_mut()
                .zip(&lens)
                .filter(|&(_, &len)| len == l + 1)
                .for_each(|(val, _)| {
                    if *val < max_prev_level {
                        *val = 0.0;  // <-- BUG 游댮 Should be max_prev_level, not 0.0
                    }
                });
        }
    }
}
```

# Evidence

## Inconsistency within the codebase

### Reference code

`deep_causality_algorithms/src/causal_discovery/surd/surd_algo_cdl.rs` (lines 395-415):

```rust
if let Some(&max_len) = lens.iter().max() {
    for l in 1..max_len {
        let max_prev_level = i1_sorted
            .iter()
            .zip(&lens)
            .filter(|&(_, &len)| len == l)
            .map(|(&val, _)| val)
            .fold(f64::NEG_INFINITY, f64::max);
        if max_prev_level.is_finite() {
            i1_sorted
                .iter_mut()
                .zip(&lens)
                .filter(|&(_, &len)| len == l + 1)
                .for_each(|(val, _)| {
                    if *val < max_prev_level {
                        *val = max_prev_level;  // Correct implementation
                    }
                });
        }
    }
}
```

### Current code

`deep_causality_algorithms/src/causal_discovery/surd/surd_algo.rs` (line 370):

```rust
if *val < max_prev_level {
    *val = 0.0;  // Incorrect: zeros out the contribution
}
```

### Contradiction

The CDL variant (`surd_algo_cdl.rs`) was created as a copy of the original algorithm to handle `Option<f64>` values with missing data. During testing and refinement (commit `4496d1b3`), the exclusion principle implementation was corrected in the CDL variant to use `*val = max_prev_level;` instead of `*val = 0.0;`. However, this fix was never backported to the original `surd_algo.rs` file, creating an inconsistency between the two implementations.

The two functions are meant to implement the same mathematical algorithm - they only differ in how they handle `None` values. The exclusion principle logic should be identical, but currently it differs in this critical line.

## Explanation

The information-theoretic exclusion principle is designed to prevent double-counting information contributions from different interaction orders. When a higher-order term (e.g., `{S1, S2}`) has specific information less than the maximum specific information of lower-order terms (e.g., `{S1}`), it means the higher-order term doesn't provide additional information beyond what the lower-order terms already capture.

**Incorrect behavior (current `surd_algo.rs`):**
- Setting `*val = 0.0` completely eliminates the contribution of this term.
- This is mathematically incorrect because the term still contributes information up to the level already captured by lower-order terms.
- The differential `di_values = diff(&final_i1)` (line 381) will then incorrectly compute the increment.

**Correct behavior (as in `surd_algo_cdl.rs`):**
- Setting `*val = max_prev_level` adjusts the term to the baseline already established by lower-order interactions.
- The differential calculation will then correctly compute only the *additional* information beyond what lower-order terms provide.
- This implements the proper exclusion principle: higher-order terms only get credit for information beyond what lower-order terms already provide.

**Example scenario:**
Suppose we have:
- `i(t; S1) = 0.8` bits (specific info for single variable S1)
- `i(t; S2) = 0.3` bits (specific info for single variable S2)
- `i(t; {S1, S2}) = 0.7` bits (specific info for the pair)

After sorting: `[0.3, 0.7, 0.8]` with labels `[{S2}, {S1,S2}, {S1}]`

Exclusion principle for `l=1` (single variables) to `l+1=2` (pairs):
- `max_prev_level = 0.8` (max of single variables)
- The pair `{S1, S2}` has value `0.7 < 0.8`

**With the bug (`*val = 0.0`):**
- Adjusted values: `[0.3, 0.0, 0.8]`
- Differences: `[0.3, -0.3, 0.8]`
- This incorrectly suggests the pair provides *negative* incremental information!

**With the fix (`*val = max_prev_level`):**
- Adjusted values: `[0.3, 0.8, 0.8]`
- Differences: `[0.3, 0.5, 0.0]`
- This correctly shows the pair doesn't provide additional information beyond the maximum single variable.

## Failing test

### Test script

The test in `deep_causality_algorithms/tests/causal_discovery/surd/exclusion_principle_bug_test.rs` demonstrates scenarios where the bug manifests:

```rust
use deep_causality_algorithms::causal_discovery::surd::{MaxOrder, surd_states};
use deep_causality_tensor::CausalTensor;

#[test]
fn test_exclusion_principle_hierarchical_adjustment() {
    let data = vec![
        0.40, 0.05,  // T=0, S1=0, S2=0/1
        0.02, 0.03,  // T=0, S1=1, S2=0/1
        0.03, 0.02,  // T=1, S1=0, S2=0/1
        0.05, 0.40,  // T=1, S1=1, S2=0/1
    ];

    let p_raw = CausalTensor::new(data, vec![2, 2, 2]).unwrap();
    let result = surd_states(&p_raw, MaxOrder::Max).unwrap();

    let mi_s1 = result.mutual_info().get(&vec![1]);
    let mi_s2 = result.mutual_info().get(&vec![2]);
    let mi_s1s2 = result.mutual_info().get(&vec![1, 2]);

    println!("MI(T;S1) = {:?}", mi_s1);
    println!("MI(T;S2) = {:?}", mi_s2);
    println!("MI(T;S1,S2) = {:?}", mi_s1s2);
}
```

### Test output

```
MI(T;S1) = Some(0.5310044064107189)
MI(T;S2) = Some(0.36569044535943407)
MI(T;S1,S2) = Some(0.5652156573100267)
```

The test passes without crashing, but the internal decomposition calculations are incorrect due to the bug. The bug doesn't cause crashes or obviously invalid outputs, making it particularly insidious - it silently produces incorrect information decompositions that could lead to wrong scientific conclusions about causal relationships.

# Full context

The SURD (Synergistic, Unique, Redundant Decomposition) algorithm is a causal discovery method that decomposes mutual information between a target variable and multiple source variables. It's implemented in two variants:

1. **`surd_states` in `surd_algo.rs`**: The original implementation for `f64` values
2. **`surd_states_cdl` in `surd_algo_cdl.rs`**: A variant that handles `Option<f64>` to support missing data

Both implementations are called by users of the `deep_causality_algorithms` crate for causal analysis. The algorithm is based on the paper "Observational causality by states and interaction type for scientific discovery" (mart칤nezs치nchez2025).

The buggy code is in the `analyze_single_target_state` function, which is called for each target state in the main decomposition loop. This function:
1. Computes specific information values for all variable combinations
2. Sorts them by magnitude
3. Applies the exclusion principle to prevent double-counting
4. Calculates differential information increments
5. Decomposes these into redundant, unique, and synergistic components

The bug affects step 3, causing incorrect adjustments that propagate through steps 4 and 5, ultimately producing incorrect final decomposition results.

## External documentation

The algorithm is based on the SURD-states method from:

**Paper reference**: "Observational causality by states and interaction type for scientific discovery" (mart칤nezs치nchez2025)

From the code documentation (`surd_algo.rs`, lines 28-43):
```
/// 3.  **Specific Mutual Information**: For every combination of source variables, the specific mutual
///     information `i(Q_f=t; Q_i)` is calculated for each target state `t`. This is based on
///     (mart칤nezs치nchez2025, Supplementary Material, Eq. S6).
/// 4.  **Decomposition Loop**: For each target state `t`, the specific information values are sorted.
///     This ordering is crucial for the decomposition. An information-theoretic exclusion principle
///     is applied to prevent double-counting, as described in (mart칤nezs치nchez2025, Fig. S2).
/// 5.  **State-Dependent Slice Calculation**: The sorted information values are differenced, and these
///     increments are used to calculate the state-dependent causal maps for redundant, unique, and
///     synergistic components. This step implements the core logic from (mart칤nezs치nchez2025,
///     Supplementary Material, Eqs. S17, S22, S28), separating positive (causal) and negative (non-causal) contributions.
```

The documentation explicitly states that the exclusion principle is meant to "prevent double-counting" and references Figure S2 of the paper. Setting values to `0.0` doesn't prevent double-counting - it eliminates contributions entirely, which is incorrect. The proper exclusion principle should adjust values to the baseline established by lower-order terms, which is exactly what `max_prev_level` represents.

# Why has this bug gone undetected?

This bug has gone undetected for several reasons:

1. **Subtle manifestation**: The bug doesn't cause crashes, panics, or obviously invalid outputs (like NaN or Inf). It produces plausible-looking numerical results that are simply mathematically incorrect.

2. **Complex algorithm**: The SURD algorithm is mathematically sophisticated, involving multiple stages of information-theoretic calculations. The bug is in an intermediate step (the exclusion principle), and its effects are obscured by subsequent processing.

3. **State-dependent calculations**: The bug affects the sorting and adjustment of specific information values on a per-target-state basis. The final aggregate results are sums over all states, which can mask the incorrect intermediate values.

4. **Test coverage gaps**: The existing tests check that the algorithm produces finite values and that certain expected properties hold (e.g., synergy for XOR, uniqueness for deterministic relationships), but they don't verify the exact numerical correctness of the exclusion principle implementation.

5. **Parallel evolution**: When the CDL variant was created (commit `925f536f`), it initially had the same bug. The bug was fixed in the CDL variant during test development (commit `4496d1b3`), but this fix was never backported to the original implementation. The two implementations evolved in parallel, and the inconsistency went unnoticed.

6. **No cross-validation**: There are no tests that directly compare outputs from `surd_states` and `surd_states_cdl` on the same data (with no `None` values), which would have revealed the discrepancy.

# Recommended fix

Change line 370 in `deep_causality_algorithms/src/causal_discovery/surd/surd_algo.rs`:

```rust
if *val < max_prev_level {
    *val = max_prev_level;  // <-- FIX 游릭
}
```

This aligns the implementation with:
1. The CDL variant (`surd_algo_cdl.rs`)
2. The mathematical intent of the exclusion principle as described in the documentation
3. The information-theoretic principle of preventing double-counting while preserving hierarchical information contributions

After fixing, both `surd_states` and `surd_states_cdl` should produce identical results on the same input data (when the CDL input has no `None` values), which can be verified with a new cross-validation test.
